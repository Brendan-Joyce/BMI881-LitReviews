# 11/4 ~ Eklund ~ Cluster failure: Why fMRI inferences for spatial extent have inflated false-positive rates.
## Literature Review:
In Dr. Eklund’s validation study “Cluster failure: Why fMRI inferences for spatial extent have inflated false positive rates”, Eklund describes a previously hypothesized but under explored source of bias that may be influencing the results fMRI data analysis. Specifically, he calls out issues with false discovery rate corrections due to a failure to account for spatial autocorrelation of fMRI readings simulated to validate the quality of their results. His analysis relies on voxel- and cluster-wise inference with one and two samples t tests on a newly available public database of de-identified fMRI data to evaluate the false discovery rate of the associated inference methods. Ultimately his findings suggest that the fMRI data processing methods he tested had up to a 70% false positive rate in the context of analyzing fMRI data. These results suggested that nearly 40,000 published studies (as quoted by Eklund) could have erroneous, false-positive results due to a reliance on the fMRI data processing tools. He suggests that to address these issues, the methods applied in this analysis instead use non-parametric permutation tests, which have considerably more stable false positive rates, to validate findings. Parallel to his analysis, Eklund’s work is evaluated by his peers Dr. Brown, Dr. Cox, and Dr. Kessler. Each calls out specific problems with Eklund’s analysis but ultimately agree that the statistical approaches that Eklund employs are sound and the problems he raises are reasonable. The scientific conversation ultimately concludes that findings from fMRI studies that used these methods have a notably high risk of being false positives and thus likely require some level of re-evaluation.

Despite the critical claims made by Dr. Eklund, I personally found the discussion spurred by this paper to be more interesting and informative to me than the paper itself. The discussants and even Dr. Eklund in his response provide a clearer outline of the study’s goals and methods than that of the original paper. The original paper is dense and filled with a lot of analytical jargon and assumptions that the reader understands which subjects are being compared in the associated statistical tests. As a complete outsider to fMRI data analysis, I was lost when I first read the paper. I did not understand the dimensionality nor proper usage of fMRI data and this paper did very little to provide examples as to how his measurements are representative of the bias he is reporting. Given this is primarily a validation study, I felt that the paper should have provided clearer background as to why the statistical assessments of the measurements still held bias. Given the short length of the manuscript, the lack of relevant case driven examples, and the analysis mistakes called out by his peers, I believe this paper may have been slightly rushed to be the first to publish on this source of bias in the advent of new public databases to house and distribute fMRI data. With that said, his findings are sound, if not a little overblown, and his remedy for the problem is effective. So, I think that overall, I find his contribution to be meaningful, if not a bit difficult to distribute to outsiders.
## Questions:
1.	If the paper was better written as to more effectively call out the basis of 40,000 potentially erroneous studies, would the media of the time still pick up this study and distribute it widely?
2.	Following that, do you believe that modern media is more or less likely to sensationalize findings from scientific research today?
3.	Given the issues with his analysis brought up by his discussants, is it healthy for scientific research more generally to laude work like this? It almost feels like the true validity of the paper was realized in the discussion that followed rather than the paper itself.

Eklund, Anders, Thomas E. Nichols, and Hans Knutsson. "Cluster failure: Why fMRI inferences for spatial extent have inflated false-positive rates." Proceedings of the national academy of sciences 113.28 (2016): 7900-7905.
